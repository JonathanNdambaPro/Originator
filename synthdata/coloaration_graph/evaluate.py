"""
Evaluates the Graph Coloring Problem using an LLM agent via Pydantic-AI.

This module orchestrates the evaluation of graph coloring problems generated by `generate.py`.
It uses an OpenRouter model via Pydantic-AI to attempt solving each graph, and then
verifies the solution against the constraints using the `verify` function.
"""

import asyncio
import json
from pathlib import Path
from typing import Any

import logfire
from dotenv import load_dotenv
from loguru import logger
from pydantic_ai import Agent

from synthdata.coloaration_graph.type import OutputExpectedGraph
from synthdata.coloaration_graph.verify import verify

load_dotenv()

logfire.configure()
logfire.instrument_pydantic_ai()

logger.configure(handlers=[logfire.loguru_handler()])


support_agent = Agent(
    "openrouter:anthropic/claude-sonnet-4-5",  # Mettre un modele qui marche comme gemini-2.5-flash or gemini-3-flash-preview si c'est bon
    deps_type=Any,
    output_type=OutputExpectedGraph,
    system_prompt=(
        "You are an expert algorithm solver for the Graph Coloring Problem. "
        "You will be given a list of nodes, a list of edges, and allowable colors. "
        "Your task is to assign exactly one color to each node such that no two "
        "adjacent nodes (connected by an edge) share the same color. "
        "Ensure all nodes are assigned a valid color from the provided list."
    ),
)


async def main() -> None:
    """
    Main evaluation routine.

    Reads the generated graph problems from `problems.json`, asks the
    LLM to solve them, verifies the result, and outputs the success ratio.

    Returns:
        None
    """
    data_path = Path(__file__).parent / "problems.json"
    if not data_path.exists():
        logger.info(f"File {data_path} not found. Please run generate.py first.")
        return

    with open(data_path, encoding="utf-8") as f:
        problems_data = json.load(f)

    success_count = 0
    total_problems = len(problems_data)

    for i, prob_data in enumerate(problems_data):
        logger.info(f"\n--- Evaluating Problem {i + 1}/{total_problems} ---")

        prompt = (
            f"Solve the graph coloring problem:\n"
            f"Nodes: {prob_data['nodes']}\n"
            f"Edges: {prob_data['edges']}\n"
            f"Colors: {prob_data['colors']}\n"
            "Return a dictionary mapping each node to its chosen color."
        )

        try:
            result = await support_agent.run(prompt)

            # Convert list of NodeColorMapping objects to dictionary
            solution_list = result.output.solution
            solution = {item.node: item.color for item in solution_list}

            is_valid = verify(solution, prob_data["edges"], prob_data["nodes"], prob_data["colors"])
            if is_valid:
                logger.success(f"âœ… Problem {i + 1} solved correctly!")
                success_count += 1
            else:
                logger.error(f"âŒ Problem {i + 1} failed verification.")
                logger.info(f"LLM Solution: {solution}")

        except Exception as e:
            logger.warning(f"âš ï¸ Error evaluating Problem {i + 1}: {e}")

    ratio = success_count / total_problems if total_problems > 0 else 0
    logger.info("\n=== Evaluation Complete ===")

    if 0.1 <= ratio <= 0.9:
        logger.success(f"ðŸŽ¯ Perfect Difficulty! Success ratio: {success_count}/{total_problems} ({ratio:.2%})")
    else:
        logger.warning(
            f"âš ï¸ Out of Bounds! Success ratio: {success_count}/{total_problems} ({ratio:.2%}). Use Typer '--num-nodes' or '--edge-probability' to adjust."
        )


if __name__ == "__main__":
    asyncio.run(main())
