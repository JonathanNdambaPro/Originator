{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Synthetic Data Generation &amp; Evaluation","text":""},{"location":"#applied-ai-engineer-take-home-exercise","title":"Applied AI Engineer \u2014 Take-Home Exercise","text":""},{"location":"#1-overview-task-selection","title":"1. Overview &amp; Task Selection","text":"<ul> <li>Task Selection (<code>x</code>): Graph Coloring (Constraint Satisfaction Problem). The LLM is given a list of nodes, edges, and allowed colors, and must assign a color to each node such that no two adjacent nodes share the same color.</li> <li>Model Choice (<code>y</code>): <code>openrouter:anthropic/claude-sonnet-4-5</code> (via Pydantic-AI with OpenRouter API integration). Can easily be swapped to any frontier model in <code>evaluate.py</code>.</li> </ul> <p>Why this task falls in the 10-90% success rate bucket: Current frontier LLMs generate text autoregressively (left-to-right) and lack native backtracking mechanisms. In a tightly constrained graph, if the model makes a sub-optimal color choice early on, it mathematically hits a dead-end later. Because it cannot \"erase\" its previous tokens, it will hallucinate a color or violate a constraint.</p> <ul> <li>Trivial (5 nodes): ~100% success.</li> <li>Sweet Spot (12 nodes, 0.4 edge probability): ~10-90% success. The model's forward-planning capacity is overloaded, causing it to randomly paint itself into a corner.</li> <li>Impossible (&gt;30 nodes): ~0% success.</li> </ul>"},{"location":"#2-synthetic-data-generation-strategy","title":"2. Synthetic Data Generation Strategy","text":"<p>Naively generating random graphs can inadvertently create NP-Hard, unsolvable problems (leading to a 0% success rate). My <code>generate.py</code> script uses a \"Planted Solution\" algorithm:</p> <ol> <li>It secretly assigns a valid color to each node.</li> <li>It randomly generates edges, but strictly prevents edges between nodes sharing the same secret color.</li> <li>It shuffles the arrays and discards the secret colors. This ensures every generated problem in <code>problems.json</code> is 100% solvable.</li> </ol>"},{"location":"#3-verification-evaluation-system","title":"3. Verification &amp; Evaluation System","text":"<ul> <li>Verification (<code>verify.py</code>): Validation is completely deterministic (\\(O(E)\\)). The script loops through the edges and strictly checks if the LLM assigned the same color to both ends of any edge.</li> <li>Evaluation (<code>evaluate.py</code>): Uses Pydantic-AI to enforce a strict JSON schema output (<code>OutputExpectedGraph</code>), eliminating brittle regex parsing. The script loops over the generated problems and calculates the exact success rate. (The LLM runs entirely locally via API without browsing the internet).</li> </ul>"},{"location":"#4-advanced-observability-logfire-loguru","title":"4. Advanced Observability (Logfire &amp; Loguru)","text":"<p>In a post-training/RLHF context, a binary \"Pass/Fail\" is insufficient. We must know why the model drifted. I instrumented the evaluation pipeline with Loguru (for rich console diagnostics) and Pydantic Logfire (OpenTelemetry for LLMs). If the model fails, the logs pinpoint the exact constraint violated.</p> <p>\u26a0\ufe0f How to use or disable Logfire</p> <ul> <li>To use it: Run <code>logfire auth</code> in your terminal to link it to your Pydantic account.</li> <li>To disable it (Opt-out): If you prefer a clean local console without sending telemetry, simply open <code>evaluate.py</code> and comment out the instrumentation lines: </li> </ul> <pre><code># logfire.configure()\n# logfire.instrument_pydantic_ai()\n</code></pre> <p>The script will gracefully fall back to standard local Loguru terminal outputs.</p>"},{"location":"#5-setup-usage-instructions","title":"5. Setup &amp; Usage Instructions","text":"<p>1. Set up Environment Variables</p> <p>Create a <code>.env</code> file in the root of the project with your API keys:</p> <pre><code>OPENROUTER_API_KEY=\"your_openrouter_api_key\"\n</code></pre> <p>(Optional) Add <code>LOGFIRE_TOKEN</code> if you wish to use remote Pydantic-AI observability.</p> <p>2. Install Dependencies</p> <p>This project relies on <code>uv</code> for lightning-fast environment management.</p> <pre><code>uv sync\n</code></pre> <p>Docker Fallback Playground</p> <p>If <code>uv</code> does not install or work on your machine, you can launch the provided Docker container as an interactive playground:</p> <pre><code>docker build -t synthdata-playground .\ndocker run -d --name synthdata-env -v $(pwd):/app synthdata-playground\ndocker exec -it synthdata-env bash\n</code></pre> <p>Once inside the container shell, you can directly run the <code>generate.py</code> and <code>evaluate.py</code> commands as described below.</p> <p>3. Generate Synthetic Data</p> <p>Run the generator script. This will create a <code>problems.json</code> file in the same directory.</p> <p>You can run the script as-is for a pre-configured acceptable complexity (~10-90% LLM success rate):</p> <pre><code>uv run synthdata/coloaration_graph/generate.py\n</code></pre> <p>OR</p> <pre><code>uv run python -m synthdata.coloaration_graph.generate\n</code></pre> <p>Adjusting Complexity You can easily increase or reduce the complexity of the generated problems by playing with the CLI arguments:</p> <ul> <li><code>--num-nodes</code>: Number of nodes in the graph (min: 3, default: 12). More nodes = harder.</li> <li><code>--num-colors</code>: Allowed number of colors (min: 1, max: 5, default: 3). Fewer colors = harder.</li> <li><code>--edge-probability</code>: Density of constraints between 0.0 and 1.0 (default: 0.4). Higher probability = harder.</li> <li><code>--num-samples</code>: Number of problems to generate (default: 30).</li> </ul> <p>Example: Generating a highly complex dataset</p> <pre><code>uv run coloaration_graph/generate.py --num-samples 50 --num-nodes 20 --num-colors 3 --edge-probability 0.6\n</code></pre> <p>4. Evaluate the LLM</p> <p>Run the evaluation script to test <code>claude-sonnet-4-5</code> via OpenRouter against the generated problems.</p> <pre><code>uv run synthdata/coloaration_graph/evaluate.py\n</code></pre> <p>OR</p> <pre><code>uv run python -m synthdata.coloaration_graph.evaluate\n</code></pre> <p>Watch the console to see if the LLM achieves the targeted 10-90% success rate!</p> <p>5. Run Verification Unit Tests</p> <p>You can run the comprehensive tests for the verification logic using pytest.</p> <pre><code>uv run pytest synthdata/coloaration_graph/tests/ -v\n</code></pre> <p>Repository initiated with fpgmaas/cookiecutter-uv.</p>"},{"location":"modules/","title":"Code Modules","text":"<p>Here is the API documentation for the primary modules in this project.</p>"},{"location":"modules/#core-logic","title":"core logic","text":"<p>Generates synthetic data for Graph Coloring Problems.</p> <p>This module provides a CLI to generate random, solvable graph coloring problems using a \"planted solution\" approach, ensuring that all generated problems have at least one valid solution.</p> <p>Evaluates the Graph Coloring Problem using an LLM agent via Pydantic-AI.</p> <p>This module orchestrates the evaluation of graph coloring problems generated by <code>generate.py</code>. It uses an OpenRouter model via Pydantic-AI to attempt solving each graph, and then verifies the solution against the constraints using the <code>verify</code> function.</p> <p>Verification module for Graph Coloring Problem solutions.</p> <p>This module provides the deterministic validation logic to check whether a given color assignment for a graph satisfies all coloring constraints.</p>"},{"location":"modules/#synthdata.coloaration_graph.generate.create_single_problem","title":"<code>create_single_problem(num_nodes, num_colors, edge_probability)</code>","text":"<p>Generates a single solvable graph coloring problem.</p> <p>Uses the 'planted solution' method by first assigning valid colors and then only creating edges between nodes with different colors.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>int</code> <p>The total number of nodes in the generated graph.</p> required <code>num_colors</code> <code>int</code> <p>The number of allowed colors.</p> required <code>edge_probability</code> <code>float</code> <p>The probability of creating an edge between two valid nodes.</p> required <p>Returns:</p> Name Type Description <code>GraphColoringProblem</code> <code>GraphColoringProblem</code> <p>A Pydantic model containing nodes, edges, and valid colors.</p> Source code in <code>synthdata/coloaration_graph/generate.py</code> <pre><code>def create_single_problem(num_nodes: int, num_colors: int, edge_probability: float) -&gt; GraphColoringProblem:\n    \"\"\"\n    Generates a single solvable graph coloring problem.\n\n    Uses the 'planted solution' method by first assigning valid colors and then\n    only creating edges between nodes with different colors.\n\n    Args:\n        num_nodes (int): The total number of nodes in the generated graph.\n        num_colors (int): The number of allowed colors.\n        edge_probability (float): The probability of creating an edge between two valid nodes.\n\n    Returns:\n        GraphColoringProblem: A Pydantic model containing nodes, edges, and valid colors.\n    \"\"\"\n    colors = [Color.RED, Color.BLUE, Color.GREEN, Color.YELLOW, Color.PURPLE][:num_colors]\n    nodes = [f\"N{i}\" for i in range(num_nodes)]\n\n    # 1. Start with a valid hidden assignment (planted solution)\n    golden_solution = {node: random.choice(colors) for node in nodes}  # noqa: S311\n\n    # 2. Iteratively build up edges (constraints)\n    edges = []\n    for i in range(num_nodes):\n        for j in range(i + 1, num_nodes):\n            node_u = nodes[i]\n            node_v = nodes[j]\n\n            # GOLDEN RULE: We ONLY connect nodes if their secret colors are different\n            if golden_solution[node_u] != golden_solution[node_v] and random.random() &lt; edge_probability:  # noqa: S311\n                edges.append((node_u, node_v))\n\n    # We shuffle the edges so the LLM cannot guess the pattern\n    random.shuffle(edges)\n\n    return GraphColoringProblem(nodes=nodes, edges=edges, colors=colors)\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.generate.generate","title":"<code>generate(num_samples=30, num_nodes=12, num_colors=3, edge_probability=0.4, output=DATA_FOLDER)</code>","text":"<p>Generates a synthetic dataset of graph coloring problems and exports it to JSON.</p> <p>Parameters:</p> Name Type Description Default <code>num_samples</code> <code>int</code> <p>Number of separate constraint-satisfaction problems to make.</p> <code>30</code> <code>num_nodes</code> <code>int</code> <p>The total number of nodes in the generated graphs.</p> <code>12</code> <code>num_colors</code> <code>int</code> <p>Allowed amount of colors to use per graph.</p> <code>3</code> <code>edge_probability</code> <code>float</code> <p>Probabilistic density for edges to appear between nodes.</p> <code>0.4</code> <code>output</code> <code>Path</code> <p>Path to output directory containing <code>problems.json</code>.</p> <code>DATA_FOLDER</code> Source code in <code>synthdata/coloaration_graph/generate.py</code> <pre><code>@app.command()\ndef generate(\n    num_samples: Annotated[int, typer.Option(\"--num-samples\", help=\"Number of problems to generate\", min=1)] = 30,\n    num_nodes: Annotated[int, typer.Option(\"--num-nodes\", help=\"Number of nodes in the graph\", min=3)] = 12,\n    num_colors: Annotated[int, typer.Option(\"--num-colors\", help=\"Number of allowed colors\", min=1, max=5)] = 3,\n    edge_probability: Annotated[\n        float, typer.Option(\"--edge-probability\", help=\"Probability of an edge existing\", min=0.0, max=1.0)\n    ] = 0.4,\n    output: Annotated[Path, typer.Option(\"--output\", help=\"Output file path (default: print to stdout)\")] = DATA_FOLDER,\n):\n    \"\"\"\n    Generates a synthetic dataset of graph coloring problems and exports it to JSON.\n\n    Args:\n        num_samples (int): Number of separate constraint-satisfaction problems to make.\n        num_nodes (int): The total number of nodes in the generated graphs.\n        num_colors (int): Allowed amount of colors to use per graph.\n        edge_probability (float): Probabilistic density for edges to appear between nodes.\n        output (Path): Path to output directory containing `problems.json`.\n    \"\"\"\n    examples = []\n\n    # We loop here (at the CLI level) to generate the requested number of problems\n    for _ in range(num_samples):\n        problem = create_single_problem(num_nodes=num_nodes, num_colors=num_colors, edge_probability=edge_probability)\n        # We convert the Pydantic model to a dict for JSON\n        examples.append(problem.model_dump())\n\n    # JSON Formatting\n    output_json = json.dumps(examples, indent=2)\n\n    # Typer and pathlib magically handle directory creation\n    output.mkdir(parents=True, exist_ok=True)\n    path_json_data = output / \"problems.json\"\n    # Write directly to the file\n    path_json_data.write_text(output_json, encoding=\"utf-8\")\n\n    # typer.secho allows writing in color to the terminal\n    typer.secho(f\"\u2705 Generated {num_samples} problems and saved to {output}\", fg=typer.colors.GREEN)\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.evaluate.main","title":"<code>main()</code>  <code>async</code>","text":"<p>Main evaluation routine.</p> <p>Reads the generated graph problems from <code>problems.json</code>, asks the LLM to solve them, verifies the result, and outputs the success ratio.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>synthdata/coloaration_graph/evaluate.py</code> <pre><code>async def main() -&gt; None:\n    \"\"\"\n    Main evaluation routine.\n\n    Reads the generated graph problems from `problems.json`, asks the\n    LLM to solve them, verifies the result, and outputs the success ratio.\n\n    Returns:\n        None\n    \"\"\"\n    data_path = Path(__file__).parent / \"problems.json\"\n    if not data_path.exists():\n        logger.info(f\"File {data_path} not found. Please run generate.py first.\")\n        return\n\n    with open(data_path, encoding=\"utf-8\") as f:\n        problems_data = json.load(f)\n\n    success_count = 0\n    total_problems = len(problems_data)\n\n    for i, prob_data in enumerate(problems_data):\n        logger.info(f\"\\n--- Evaluating Problem {i + 1}/{total_problems} ---\")\n\n        prompt = (\n            f\"Solve the graph coloring problem:\\n\"\n            f\"Nodes: {prob_data['nodes']}\\n\"\n            f\"Edges: {prob_data['edges']}\\n\"\n            f\"Colors: {prob_data['colors']}\\n\"\n            \"Return a dictionary mapping each node to its chosen color.\"\n        )\n\n        try:\n            result = await support_agent.run(prompt)\n\n            # Convert list of NodeColorMapping objects to dictionary\n            solution_list = result.output.solution\n            solution = {item.node: item.color for item in solution_list}\n\n            is_valid = verify(solution, prob_data[\"edges\"], prob_data[\"nodes\"], prob_data[\"colors\"])\n            if is_valid:\n                logger.success(f\"\u2705 Problem {i + 1} solved correctly!\")\n                success_count += 1\n            else:\n                logger.error(f\"\u274c Problem {i + 1} failed verification.\")\n                logger.info(f\"LLM Solution: {solution}\")\n\n        except Exception as e:\n            logger.warning(f\"\u26a0\ufe0f Error evaluating Problem {i + 1}: {e}\")\n\n    ratio = success_count / total_problems if total_problems &gt; 0 else 0\n    logger.info(\"\\n=== Evaluation Complete ===\")\n\n    if 0.1 &lt;= ratio &lt;= 0.9:\n        logger.success(f\"\ud83c\udfaf Perfect Difficulty! Success ratio: {success_count}/{total_problems} ({ratio:.2%})\")\n    else:\n        logger.warning(\n            f\"\u26a0\ufe0f Out of Bounds! Success ratio: {success_count}/{total_problems} ({ratio:.2%}). Use Typer '--num-nodes' or '--edge-probability' to adjust.\"\n        )\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.verify.verify","title":"<code>verify(reponse_llm, edges, expected_nodes, allowed_colors)</code>","text":"<p>Verifies the correctness of a proposed graph coloring solution.</p> <p>Checks three conditions: 1. Every node in the expected graph has been assigned a color. 2. All assigned colors are valid choices from the allowed list. 3. No two connected nodes share the same color.</p> <p>Parameters:</p> Name Type Description Default <code>reponse_llm</code> <code>dict[str, str]</code> <p>Dictionary mapping node IDs to their assigned color strings.</p> required <code>edges</code> <code>list[tuple[str, str]]</code> <p>List of tuples representing the graph edges between nodes.</p> required <code>expected_nodes</code> <code>list[str]</code> <p>List of all node IDs that must exist in the solution.</p> required <code>allowed_colors</code> <code>list[str]</code> <p>List of valid color strings that can be used.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the graph is properly colored and valid according to constraints, False otherwise.</p> Source code in <code>synthdata/coloaration_graph/verify.py</code> <pre><code>def verify(\n    reponse_llm: dict[str, str], edges: list[tuple[str, str]], expected_nodes: list[str], allowed_colors: list[str]\n) -&gt; bool:\n    \"\"\"\n    Verifies the correctness of a proposed graph coloring solution.\n\n    Checks three conditions:\n    1. Every node in the expected graph has been assigned a color.\n    2. All assigned colors are valid choices from the allowed list.\n    3. No two connected nodes share the same color.\n\n    Args:\n        reponse_llm (dict[str, str]): Dictionary mapping node IDs to their assigned color strings.\n        edges (list[tuple[str, str]]): List of tuples representing the graph edges between nodes.\n        expected_nodes (list[str]): List of all node IDs that must exist in the solution.\n        allowed_colors (list[str]): List of valid color strings that can be used.\n\n    Returns:\n        bool: True if the graph is properly colored and valid according to constraints, False otherwise.\n    \"\"\"\n    # 1. Verify that all nodes have been assigned a color\n    if set(reponse_llm.keys()) != set(expected_nodes):\n        return False\n\n    # 2. Verify that the used colors are among the allowed colors\n    # We first ensure the colors provided by the LLM match the Color Enum values\n    valid_color_values = [color.value for color in Color]\n    for color in reponse_llm.values():\n        if color not in valid_color_values or color not in allowed_colors:\n            return False\n\n    # 3. Verify the main constraint: no edge connects two identical colors\n    # get() instead of [] just in case, although step 1 handles missing keys already\n    return all(reponse_llm.get(noeud_A) != reponse_llm.get(noeud_B) for noeud_A, noeud_B in edges)\n</code></pre>"},{"location":"modules/#configuration-types","title":"configuration &amp; types","text":"<p>Data models and types for the Graph Coloring Problem.</p> <p>Defines Pydantic models for structured validation of inputs, LLM outputs, and graph representations to ensure type safety across the application.</p>"},{"location":"modules/#synthdata.coloaration_graph.type.Color","title":"<code>Color</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumeration of allowed colors for the graph nodes.</p> Source code in <code>synthdata/coloaration_graph/type.py</code> <pre><code>class Color(StrEnum):\n    \"\"\"\n    Enumeration of allowed colors for the graph nodes.\n    \"\"\"\n\n    RED = auto()\n    BLUE = auto()\n    GREEN = auto()\n    YELLOW = auto()\n    PURPLE = auto()\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.type.GraphColoringProblem","title":"<code>GraphColoringProblem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structured definition of a complete graph coloring problem.</p> Source code in <code>synthdata/coloaration_graph/type.py</code> <pre><code>class GraphColoringProblem(BaseModel):\n    \"\"\"\n    Structured definition of a complete graph coloring problem.\n    \"\"\"\n\n    nodes: list[str]\n    edges: list[tuple[str, str]]\n    colors: list[Color]\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.type.Node","title":"<code>Node</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single node in the graph.</p> Source code in <code>synthdata/coloaration_graph/type.py</code> <pre><code>class Node(BaseModel):\n    \"\"\"\n    Represents a single node in the graph.\n    \"\"\"\n\n    node: str = Field(..., pattern=r\"^N\\d+$\")\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.type.NodeColorMapping","title":"<code>NodeColorMapping</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an assignment of a specific color to a specific node.</p> Source code in <code>synthdata/coloaration_graph/type.py</code> <pre><code>class NodeColorMapping(BaseModel):\n    \"\"\"\n    Represents an assignment of a specific color to a specific node.\n    \"\"\"\n\n    node: str\n    color: Color\n</code></pre>"},{"location":"modules/#synthdata.coloaration_graph.type.OutputExpectedGraph","title":"<code>OutputExpectedGraph</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The strictly formatted JSON output expected from the LLM solution.</p> Source code in <code>synthdata/coloaration_graph/type.py</code> <pre><code>class OutputExpectedGraph(BaseModel):\n    \"\"\"\n    The strictly formatted JSON output expected from the LLM solution.\n    \"\"\"\n\n    solution: list[NodeColorMapping] = Field(\n        ..., description=\"List associating each node with its color (e.g., [{'node': 'N0', 'color': 'Red'}, ...]).\"\n    )\n</code></pre>"}]}